{\rtf1\ansi\ansicpg1252\cocoartf2512
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica-Bold;\f1\fswiss\fcharset0 Helvetica;\f2\fswiss\fcharset0 Helvetica-Oblique;
\f3\fmodern\fcharset0 Courier;\f4\fswiss\fcharset0 Helvetica-BoldOblique;}
{\colortbl;\red255\green255\blue255;\red35\green46\blue57;\red62\green62\blue62;\red14\green32\blue46;
\red245\green245\blue246;\red21\green163\blue221;\red255\green255\blue255;}
{\*\expandedcolortbl;;\cssrgb\c18039\c23922\c28627;\cssrgb\c30980\c30980\c30980;\cssrgb\c5882\c16863\c23922;
\cssrgb\c96863\c96863\c97255;\cssrgb\c784\c70196\c89412;\cssrgb\c100000\c100000\c100000;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid101\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid2}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\sl480\sa100\partightenfactor0

\f0\b\fs36 \cf2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Optimizing skewness\
\pard\pardeftab720\sl426\sa100\partightenfactor0

\fs32 \cf2 Use Cases in Business Datasets\
\pard\pardeftab720\sl400\sa300\partightenfactor0

\f1\b0\fs24 \cf3 \strokec3 Skewed datasets are common. In fact, you are bound to encounter skewed data on a regular basis. In the video above, the instructor describes a year-long worth of retail business\'92 data. As one might expect, retail business is likely to surge during Thanksgiving and Christmas, while the rest of the year would be pretty flat.\'a0
\f2\i Skewed data indicators:
\f1\i0 \'a0If we were to look at that data,\'a0
\f2\i partitioned by month
\f1\i0 , we would have a large volume during November and December. We would like to\'a0
\f0\b process this dataset through Spark using different partitions
\f1\b0 , if possible.\'a0
\f2\i What are some ways to solve skewness?
\f1\i0 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl400\partightenfactor0
\ls1\ilvl0\cf3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 Data preprocess\
\ls1\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 Broadcast joins\
\ls1\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 Salting\
\pard\pardeftab720\sl480\sa100\partightenfactor0

\f0\b\fs36 \cf2 \strokec2 So how do we solve skewed data problems?\
\pard\pardeftab720\sl400\sa300\partightenfactor0

\f1\b0\fs24 \cf3 \strokec3 The goal is to change the partitioning columns to take out the data skewness (e.g., the\'a0
\f3 \cf4 \cb5 \strokec4 \uc0\u8237 year
\f1 \cf3 \cb1 \strokec3 \uc0\u8236 \'a0column is skewed).\
\pard\pardeftab720\sl373\sa100\partightenfactor0

\f0\b\fs28 \cf3 1.\'a0Use Alternate Columns that are more normally distributed:\uc0\u8232 \
\pard\pardeftab720\sl400\sa300\partightenfactor0

\f1\b0\fs24 \cf3 E.g., Instead of the\'a0
\f3 \cf4 \cb5 \strokec4 \uc0\u8237 year
\f1 \cf3 \cb1 \strokec3 \uc0\u8236 \'a0column, we can use\'a0
\f3 \cf4 \cb5 \strokec4 \uc0\u8237 Issue_Date
\f1 \cf3 \cb1 \strokec3 \uc0\u8236 \'a0column that isn\'92t skewed.\uc0\u8232 \
\pard\pardeftab720\sl373\sa100\partightenfactor0

\f0\b\fs28 \cf3 2.\'a0Make Composite Keys:\uc0\u8232 \
\pard\pardeftab720\sl400\sa300\partightenfactor0

\f1\b0\fs24 \cf3 For e.g., you can make composite keys by combining two columns so that the new column can be used as a composite key. For e.g, combining the\'a0
\f3 \cf4 \cb5 \strokec4 \uc0\u8237 Issue_Date
\f1 \cf3 \cb1 \strokec3 \uc0\u8236 \'a0and\'a0
\f3 \cf4 \cb5 \strokec4 \uc0\u8237 State
\f1 \cf3 \cb1 \strokec3 \uc0\u8236 \'a0columns to make a new composite key titled\'a0
\f3 \cf4 \cb5 \strokec4 \uc0\u8237 Issue_Date + State
\f1 \cf3 \cb1 \strokec3 \uc0\u8236 . The\'a0
\f0\b new
\f1\b0 \'a0column will now include data from 2 columns, e.g.,\'a0
\f3 \cf4 \cb5 \strokec4 \uc0\u8237 2017-04-15-NY
\f1 \cf3 \cb1 \strokec3 \uc0\u8236 . This column can be used to partition the data, create more normally distributed datasets (e.g., distribution of parking violations on 2017-04-15 would now be more spread out across states, and this can now help address skewness in the data.\
\pard\pardeftab720\sl373\sa100\partightenfactor0

\f0\b\fs28 \cf3 3.\'a0Partition by number of Spark workers:\uc0\u8232 \
\pard\pardeftab720\sl400\partightenfactor0

\f1\b0\fs24 \cf3 Another easy way is using the Spark workers. If you know the number of your workers for Spark, then you can easily partition the data by the number of workers\'a0
\f3 \cf4 \cb5 \strokec4 \uc0\u8237 df.repartition(number_of_workers)
\f1 \cf3 \cb1 \strokec3 \uc0\u8236 \'a0to repartition your data evenly across your workers. For example, if you have 8 workers, then you should do\'a0
\f3 \cf4 \cb5 \strokec4 \uc0\u8237 df.repartition(8)
\f1 \cf3 \cb1 \strokec3 \uc0\u8236 \'a0before doing any operations.\
\pard\pardeftab720\sl400\partightenfactor0

\fs30 \cf3 \
\pard\pardeftab720\sl400\sa300\partightenfactor0

\fs24 \cf3 In the above video, the instructor describes her two approaches and provides an example of the\'a0
\f2\i repartition
\f1\i0 \'a0method.\
\pard\pardeftab720\sl480\sa100\partightenfactor0

\f0\b\fs36 \cf2 \strokec2 Optimizing skewness\
\pard\pardeftab720\sl400\sa300\partightenfactor0

\f1\b0\fs24 \cf3 \strokec3 Let\'92s recap how I solved the skewed data problem.\uc0\u8232 I would like to use two different ways to solve this problem.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl400\partightenfactor0
\ls2\ilvl0\cf3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 I would like to\'a0
\f0\b assign a new, temporary partition key
\f1\b0 \'a0before processing any huge shuffles.\
\ls2\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 The second method is using\'a0
\f0\b repartition
\f1\b0 .\
\pard\pardeftab720\sl533\sa100\partightenfactor0

\f0\b\fs40 \cf2 \strokec2 Practice Optimizing Skewness\
\pard\pardeftab720\sl400\sa300\partightenfactor0

\f1\b0\fs24 \cf3 \strokec3 Here is a link to the starter code for you to\'a0{\field{\*\fldinst{HYPERLINK "https://github.com/udacity/nd027-c3-data-lakes-with-spark/tree/master/Debugging_And_Optimization/exercises/starter"}}{\fldrslt \cf6 \strokec6 practice repartitioning}}\'a0to address challenges with Skewed data.\
\pard\pardeftab720\sl426\partightenfactor0

\f0\b\fs32 \cf2 \strokec2 You will find the zipped Parking_violations.csv file below. This file is\'a0
\f4\i not
\f0\i0 \'a0available in the gitrepo because of its size.\
\
\pard\pardeftab720\sl308\partightenfactor0

\f1\b0\fs23\fsmilli11550 \cf2 \cb7 Supporting Materials\
\pard\pardeftab720\sl373\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://video.udacity-data.com/topher/2020/May/5eabed5e_parking-violation.csv/parking-violation.csv.zip"}}{\fldrslt 
\f0\b\fs28 \cf6 \strokec6 \'a0Parking Violation.Csv}}
\f0\b\fs28 \cf3 \cb1 \strokec3 \
\pard\pardeftab720\sl426\partightenfactor0

\fs32 \cf2 \strokec2 \
}