{\rtf1\ansi\ansicpg1252\cocoartf2512
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica-Bold;\f1\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;\red35\green46\blue57;\red62\green62\blue62;\red21\green163\blue221;
}
{\*\expandedcolortbl;;\cssrgb\c18039\c23922\c28627;\cssrgb\c30980\c30980\c30980;\cssrgb\c784\c70196\c89412;
}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid101\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid2}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\sl640\sa100\partightenfactor0

\f0\b\fs48 \cf2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Spark Use Cases and Resources\
\pard\pardeftab720\sl400\sa300\partightenfactor0

\f1\b0\fs24 \cf3 \strokec3 Here are a few resources about different Spark use cases:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl400\partightenfactor0
\ls1\ilvl0
\f0\b \cf4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}{\field{\*\fldinst{HYPERLINK "http://spark.apache.org/sql/"}}{\fldrslt \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Data Analytics}}
\f1\b0 \cf3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 \
\ls1\ilvl0
\f0\b \cf4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}{\field{\*\fldinst{HYPERLINK "http://spark.apache.org/mllib/"}}{\fldrslt \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Machine Learning}}
\f1\b0 \cf3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 \
\ls1\ilvl0
\f0\b \cf4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}{\field{\*\fldinst{HYPERLINK "http://spark.apache.org/streaming/"}}{\fldrslt \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Streaming}}
\f1\b0 \cf3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 \
\ls1\ilvl0
\f0\b \cf4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}{\field{\*\fldinst{HYPERLINK "http://spark.apache.org/graphx/"}}{\fldrslt \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Graph Analytics}}
\f1\b0 \cf3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 \
\pard\pardeftab720\sl640\sa100\partightenfactor0

\f0\b\fs48 \cf2 \strokec2 You Don't Always Need Spark\
\pard\pardeftab720\sl400\sa300\partightenfactor0

\f1\b0\fs24 \cf3 \strokec3 Spark is meant for big data sets that cannot fit on one computer. But you don't need Spark if you are working on smaller data sets. In the cases of data sets that can fit on your local computer, there are many other options out there you can use to manipulate data such as:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl400\partightenfactor0
\ls2\ilvl0
\f0\b \cf4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}{\field{\*\fldinst{HYPERLINK "https://en.wikipedia.org/wiki/AWK"}}{\fldrslt \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 AWK}}
\f1\b0 \cf3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 \'a0- a command line tool for manipulating text files\
\ls2\ilvl0
\f0\b \cf4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}{\field{\*\fldinst{HYPERLINK "https://www.r-project.org/"}}{\fldrslt \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 R}}
\f1\b0 \cf3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 \'a0- a programming language and software environment for statistical computing\
\ls2\ilvl0
\f0\b \cf4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}{\field{\*\fldinst{HYPERLINK "https://pydata.org/downloads.html"}}{\fldrslt \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Python PyData Stack}}
\f1\b0 \cf3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 , which includes pandas, Matplotlib, NumPy, and scikit-learn among other libraries\
\pard\pardeftab720\sl400\sa300\partightenfactor0
\cf3 Sometimes, you can still use pandas on a single, local machine even if your data set is only a little bit larger than memory. Pandas can read data in chunks. Depending on your use case, you can filter the data and write out the relevant parts to disk.\
If the data is already stored in a relational database such as\'a0{\field{\*\fldinst{HYPERLINK "https://www.mysql.com/"}}{\fldrslt 
\f0\b \cf4 \strokec4 MySQL}}\'a0or\'a0{\field{\*\fldinst{HYPERLINK "https://www.postgresql.org/"}}{\fldrslt 
\f0\b \cf4 \strokec4 Postgres}}, you can leverage SQL to extract, filter and aggregate the data. If you would like to leverage pandas and SQL simultaneously, you can use libraries such as\'a0{\field{\*\fldinst{HYPERLINK "https://www.sqlalchemy.org/"}}{\fldrslt 
\f0\b \cf4 \strokec4 SQLAlchemy}}, which provides an abstraction layer to manipulate SQL tables with generative Python expressions.\
\pard\pardeftab720\sl400\partightenfactor0
\cf3 The most commonly used Python Machine Learning library is\'a0{\field{\*\fldinst{HYPERLINK "http://scikit-learn.org/stable/"}}{\fldrslt 
\f0\b \cf4 \strokec4 scikit-learn}}. It has a wide range of algorithms for classification, regression, and clustering, as well as utilities for preprocessing data, fine tuning model parameters and testing their results. However, if you want to use more complex algorithms - like deep learning - you'll need to look further.\'a0{\field{\*\fldinst{HYPERLINK "https://www.tensorflow.org/"}}{\fldrslt 
\f0\b \cf4 \strokec4 TensorFlow}}\'a0and\'a0{\field{\*\fldinst{HYPERLINK "https://pytorch.org/"}}{\fldrslt 
\f0\b \cf4 \strokec4 PyTorch}}\'a0are currently popular packages.\
\pard\pardeftab720\sl640\sa100\partightenfactor0

\f0\b\fs48 \cf2 \strokec2 Spark's Limitations\
\pard\pardeftab720\sl400\sa300\partightenfactor0

\f1\b0\fs24 \cf3 \strokec3 Spark has some limitation.\
Spark Streaming\'92s latency is at least 500 milliseconds since it operates on micro-batches of records, instead of processing one record at a time. Native streaming tools such as\'a0{\field{\*\fldinst{HYPERLINK "http://storm.apache.org/"}}{\fldrslt 
\f0\b \cf4 \strokec4 Storm}},\'a0{\field{\*\fldinst{HYPERLINK "https://apex.apache.org/"}}{\fldrslt 
\f0\b \cf4 \strokec4 Apex}}, or\'a0{\field{\*\fldinst{HYPERLINK "https://flink.apache.org/"}}{\fldrslt 
\f0\b \cf4 \strokec4 Flink}}\'a0can push down this latency value and might be more suitable for low-latency applications. Flink and Apex can be used for batch computation as well, so if you're already using them for stream processing, there's no need to add Spark to your stack of technologies.\
\pard\pardeftab720\sl400\partightenfactor0
\cf3 Another limitation of Spark is its selection of machine learning algorithms. Currently, Spark only supports algorithms that scale linearly with the input data size. In general, deep learning is not available either, though there are many projects integrate Spark with Tensorflow and other deep learning tools.\
\pard\pardeftab720\sl640\sa100\partightenfactor0

\f0\b\fs48 \cf2 \strokec2 Hadoop versus Spark\
\pard\pardeftab720\sl400\sa300\partightenfactor0

\f1\b0\fs24 \cf3 \strokec3 The Hadoop ecosystem is a slightly older technology than the Spark ecosystem. In general, Hadoop MapReduce is slower than Spark because Hadoop writes data out to disk during intermediate steps. However, many big companies, such as Facebook and LinkedIn, started using Big Data early and built their infrastructure around the Hadoop ecosystem.\
\pard\pardeftab720\sl400\partightenfactor0
\cf3 While Spark is great for iterative algorithms, there is not much of a performance boost over Hadoop MapReduce when doing simple counting. Migrating legacy code to Spark, especially on hundreds of nodes that are already in production, might not be worth the cost for the small performance boost.\
\pard\pardeftab720\sl640\sa100\partightenfactor0

\f0\b\fs48 \cf2 \strokec2 Beyond Spark for Storing and Processing Big Data\
\pard\pardeftab720\sl400\sa300\partightenfactor0

\f1\b0\fs24 \cf3 \strokec3 Keep in mind that Spark is not a data storage system, and there are a number of tools besides Spark that can be used to process and analyze large datasets.\
Sometimes it makes sense to use the power and simplicity of SQL on big data. For these cases, a new class of databases, know as NoSQL and NewSQL, have been developed.\
For example, you might hear about newer database storage systems like\'a0{\field{\*\fldinst{HYPERLINK "https://hbase.apache.org/"}}{\fldrslt 
\f0\b \cf4 \strokec4 HBase}}\'a0or\'a0{\field{\*\fldinst{HYPERLINK "http://cassandra.apache.org/"}}{\fldrslt 
\f0\b \cf4 \strokec4 Cassandra}}. There are also distributed SQL engines like\'a0{\field{\*\fldinst{HYPERLINK "https://impala.apache.org/"}}{\fldrslt 
\f0\b \cf4 \strokec4 Impala}}\'a0and\'a0{\field{\*\fldinst{HYPERLINK "https://prestodb.io/"}}{\fldrslt 
\f0\b \cf4 \strokec4 Presto}}. Many of these technologies use query syntax that you are likely already familiar with based on your experiences with Python and SQL.\
\pard\pardeftab720\sl400\partightenfactor0
\cf3 In the lessons ahead, you will learn about Spark specifically, but know that many of the skills you already have with SQL, Python, and soon enough, Spark, will also be useful if you end up needing to learn any of these additional Big Data tools.\
}