{\rtf1\ansi\ansicpg1252\cocoartf2513
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica-Bold;\f1\fswiss\fcharset0 Helvetica;\f2\fswiss\fcharset0 Helvetica-Oblique;
}
{\colortbl;\red255\green255\blue255;\red35\green46\blue57;\red255\green255\blue255;\red62\green62\blue62;
\red21\green163\blue221;}
{\*\expandedcolortbl;;\cssrgb\c18039\c23922\c28627;\cssrgb\c100000\c100000\c100000;\cssrgb\c30980\c30980\c30980;
\cssrgb\c784\c70196\c89412;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\b\fs36 \cf2 \cb3 \expnd0\expndtw0\kerning0
Defining New Terms\cb1 \
\pard\pardeftab720\partightenfactor0

\f1\b0\fs32 \cf4 \cb3 The video above includes references to a few terms that you may not be familiar with. Below are some definitions that you might find useful.\cb1 \
\pard\pardeftab720\partightenfactor0

\f0\b \cf2 \cb3 Extract Transform Load (ETL) and Extract Load Transform (ELT):\cb1 \
\pard\pardeftab720\partightenfactor0

\f1\b0 \cf4 \cb3 "ETL is normally a continuous, ongoing process with a well-defined workflow. ETL first extracts data from homogeneous or heterogeneous data sources. Then, data is cleansed, enriched, transformed, and stored either back in the lake or in a data warehouse.\cb1 \
\cb3 "ELT (Extract, Load, Transform) is a variant of ETL wherein the extracted data is first loaded into the target system. Transformations are performed after the data is loaded into the data warehouse. ELT typically works well when the target system is powerful enough to handle transformations. Analytical databases like Amazon Redshift and Google BigQ." \cb1 \
\pard\pardeftab720\partightenfactor0

\f2\i \cf4 \cb3 Source:
\f1\i0  {\field{\*\fldinst{HYPERLINK "https://www.xplenty.com/blog/etl-vs-elt/"}}{\fldrslt \cf5 Xplenty.com}}\cb1 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3 This {\field{\*\fldinst{HYPERLINK "https://www.quora.com/What-is-the-difference-between-the-ETL-and-ELT"}}{\fldrslt \cf5 Quora post}} is also helpful if you'd like to read more.\cb1 \
\pard\pardeftab720\partightenfactor0

\f0\b \cf2 \cb3 What is S3?\cb1 \
\pard\pardeftab720\partightenfactor0

\f1\b0 \cf4 \cb3 "Amazon S3 has a simple web services interface that you can use to store and retrieve any amount of data, at any time, from anywhere on the web. It gives any developer access to the same highly scalable, reliable, fast, inexpensive data storage infrastructure that Amazon uses to run its own global network of web sites." \cb1 \
\pard\pardeftab720\partightenfactor0

\f2\i \cf4 \cb3 Source:
\f1\i0  {\field{\*\fldinst{HYPERLINK "https://docs.aws.amazon.com/AmazonS3/latest/dev/Welcome.html"}}{\fldrslt \cf5 Amazon Web Services Documentation}}.\cb1 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3 If you want to learn more, start {\field{\*\fldinst{HYPERLINK "https://docs.aws.amazon.com/AmazonS3/latest/dev/Welcome.html"}}{\fldrslt \cf5 here}}.\cb1 \
\pard\pardeftab720\partightenfactor0

\f0\b \cf2 \cb3 What is Kafka?\cb1 \
\pard\pardeftab720\partightenfactor0

\f1\b0 \cf4 \cb3 "Apache Kafka is an 
\f0\b open-source stream-processing software platform
\f1\b0  developed by Linkedin and donated to the Apache Software Foundation, written in Scala and Java. The project aims to provide a unified, high-throughput, low-latency platform for handling real-time data feeds. Its storage layer is essentially a massively scalable pub/sub message queue designed as a distributed transaction log, making it highly valuable for enterprise infrastructures to process streaming data." \cb1 \
\pard\pardeftab720\partightenfactor0

\f2\i \cf4 \cb3 Source:
\f1\i0  
\f2\i Wikipedia
\f1\i0 .\cb1 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3 If you want to learn more, start {\field{\*\fldinst{HYPERLINK "https://kafka.apache.org/intro"}}{\fldrslt \cf5 here}}.\cb1 \
\pard\pardeftab720\partightenfactor0

\f0\b \cf2 \cb3 What is RedShift?\cb1 \
\pard\pardeftab720\partightenfactor0

\f1\b0 \cf4 \cb3 "Amazon Redshift is a fully managed, petabyte-scale data warehouse service in the cloud. You can start with just a few hundred gigabytes of data and scale to a petabyte or more... The first step to create a data warehouse is to launch a set of nodes, called an Amazon Redshift cluster. After you provision your cluster, you can upload your data set and then perform data analysis queries. Regardless of the size of the data set, Amazon Redshift offers fast query performance using the same SQL-based tools and business intelligence applications that you use today.\cb1 \
\cb3 If you want to learn more, start {\field{\*\fldinst{HYPERLINK "https://docs.aws.amazon.com/redshift/latest/mgmt/welcome.html"}}{\fldrslt \cf5 here}}.\cb1 \
\cb3 So in other words, S3 is an example of the final data store where data might be loaded (e.g. ETL). While Redshift is an example of a data warehouse product, provided specifically by Amazon.}